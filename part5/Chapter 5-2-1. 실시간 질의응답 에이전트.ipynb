{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPlb88K0+4MHO3fJ60w/9bU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"id":"h8oLa_dMSJHL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756089024797,"user_tz":-540,"elapsed":72155,"user":{"displayName":"Sungmin Han","userId":"16133717747299446002"}},"outputId":"983c6ec4-bfd9-46f3-9c16-33a16d98e94c"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for langchain-community (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n","cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n","tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\n","google-adk 1.11.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["#@title 1. 의존성 패키지 설치\n","!pip install -q langchain langchain-chroma langchain-openai wikipedia ddgs\n","\n","# langchain-community 최신 버전 설치 (ddgs 패키지 지원을 위하여)\n","!pip install -q --force-reinstall git+https://github.com/langchain-ai/langchain-community.git@main#subdirectory=libs/community"]},{"cell_type":"code","source":["!pip show langchain-community"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gv16A2XN8k7j","executionInfo":{"status":"ok","timestamp":1756089028114,"user_tz":-540,"elapsed":3319,"user":{"displayName":"Sungmin Han","userId":"16133717747299446002"}},"outputId":"c4a302a8-43f2-4fdd-dab1-08acaf55abff"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: langchain-community\n","Version: 0.3.27\n","Summary: Community contributed LangChain integrations.\n","Home-page: \n","Author: \n","Author-email: \n","License: MIT\n","Location: /usr/local/lib/python3.12/dist-packages\n","Requires: aiohttp, dataclasses-json, httpx-sse, langchain, langchain-core, langsmith, numpy, pydantic-settings, PyYAML, requests, SQLAlchemy, tenacity\n","Required-by: \n"]}]},{"cell_type":"code","source":["import os\n","\n","from langchain.tools import tool\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.tools import DuckDuckGoSearchRun\n","from langchain_community.document_loaders import DirectoryLoader, TextLoader\n","from langchain_openai import ChatOpenAI\n","from langchain_chroma import Chroma\n","from langchain_openai import OpenAIEmbeddings\n","from langchain.chains import create_retrieval_chain\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from langchain.chains import create_history_aware_retriever\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from google.colab import userdata\n","import wikipedia"],"metadata":{"id":"ZnExs3saU9xP","executionInfo":{"status":"ok","timestamp":1756089028168,"user_tz":-540,"elapsed":51,"user":{"displayName":"Sungmin Han","userId":"16133717747299446002"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")"],"metadata":{"id":"uqmwQ7ixaFDm","executionInfo":{"status":"ok","timestamp":1756089028665,"user_tz":-540,"elapsed":499,"user":{"displayName":"Sungmin Han","userId":"16133717747299446002"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#@title 2. 도구 1: AI 역사 백과사전 Q&A 도구\n","\n","# 한국어 위키피디아로 언어 설정\n","wikipedia.set_lang(\"ko\")\n","\n","# 지식 베이스로 사용할 문서 주제 목록\n","topics = [\"인공지능\", \"머신러닝\", \"딥러닝\"]\n","\n","# 수집된 내용을 저장할 디렉토리 생성\n","os.makedirs(\"ai_wiki_docs\", exist_ok=True)\n","\n","for topic in topics:\n","    print(f\"'{topic}' 주제의 위키피디아 문서를 수집합니다...\")\n","    try:\n","        # 위키피디아에서 해당 주제의 페이지 객체를 가져옴\n","        page = wikipedia.page(topic, auto_suggest=False)\n","\n","        # 페이지의 전체 텍스트 내용을 파일로 저장\n","        with open(f\"ai_wiki_docs/{topic}.txt\", \"w\", encoding=\"utf-8\") as f:\n","            f.write(page.content)\n","        print(f\"'{topic}.txt' 파일 저장 완료.\")\n","    except wikipedia.exceptions.PageError:\n","        print(f\"'{topic}'에 대한 위키피디아 페이지를 찾을 수 없습니다.\")\n","    except wikipedia.exceptions.DisambiguationError as e:\n","        print(f\"'{topic}'에 대한 여러 페이지가 있어 명확한 지정이 필요합니다: {e.options}\")\n","\n","llm = ChatOpenAI(\n","    model_name=\"gpt-5-mini\",\n","    api_key=OPENAI_API_KEY,\n",")\n","loader = DirectoryLoader(\n","    \"./ai_wiki_docs\",\n","    glob=\"*.txt\",\n","    loader_cls=TextLoader,\n","    loader_kwargs={\"encoding\": \"utf-8\"}\n",")\n","documents = loader.load()\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","splits = text_splitter.split_documents(documents)\n","vectorstore = Chroma.from_documents(\n","    documents=splits,\n","    embedding=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY),\n","    persist_directory=\"./chroma_db_ai_project\"\n",")\n","retriever = vectorstore.as_retriever()\n","rephrasing_prompt = ChatPromptTemplate.from_messages([\n","    MessagesPlaceholder(variable_name=\"chat_history\"),\n","    (\"user\", \"{input}\"),\n","    (\"user\", \"주어진 대화 기록을 바탕으로, 후속 질문을 검색에 사용할 수 있는 독립적인 질문으로 바꾸어주세요.\"),\n","])\n","\n","history_aware_retriever = create_history_aware_retriever(llm, retriever, rephrasing_prompt)\n","answer_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"\"\"당신은 AI 전문가입니다. 당신의 임무는 오직 주어진 문맥(context) 정보만을 사용하여 사용자의 질문에 답변하는 것입니다.\n","\n","- 답변의 근거가 된 출처 문서의 이름을 항상 명시해야 합니다. (예: [출처: 인공지능.txt])\n","\n","- 문맥 정보에 질문에 대한 답변이 포함되어 있지 않다면, 당신의 기존 지식을 활용하지 말고 반드시 \"죄송하지만, 제가 가진 정보 내에서는 답변을 찾을 수 없습니다.\"라고만 답변하세요.\n","\n","- 절대 외부 정보를 사용하거나 답변을 지어내지 마세요.\"\"\"),\n","    MessagesPlaceholder(variable_name=\"chat_history\"),\n","    (\"user\", \"{input}\"),\n","    (\"system\", \"--- 검색된 문맥 ---\\n{context}\\n--- 문맥 끝 ---\"),\n","])\n","document_chain = create_stuff_documents_chain(llm, answer_prompt)\n","conversational_rag_chain = create_retrieval_chain(history_aware_retriever, document_chain)\n","\n","\n","@tool\n","def ai_history_qa_tool(query: str) -> str:\n","    \"\"\"'인공지능(AI) 역사', '튜링 테스트', '다트머스 워크숍', '머신러닝', '딥러닝'의 역사나 개념에 대한 질문에 답변할 때 사용합니다.\n","    이 도구는 신뢰할 수 있는 내부 문서 기반으로 답변합니다.\"\"\"\n","    # 대화형 체인이므로, 빈 대화 기록과 함께 호출\n","    response = conversational_rag_chain.invoke({\n","        \"chat_history\": [],\n","        \"input\": query\n","    })\n","    return response[\"answer\"]"],"metadata":{"id":"7yHFmf8wU_cR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756089038774,"user_tz":-540,"elapsed":10099,"user":{"displayName":"Sungmin Han","userId":"16133717747299446002"}},"outputId":"cc732052-3621-40ee-f408-41fdc7a809d0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["'인공지능' 주제의 위키피디아 문서를 수집합니다...\n","'인공지능.txt' 파일 저장 완료.\n","'머신러닝' 주제의 위키피디아 문서를 수집합니다...\n","'머신러닝.txt' 파일 저장 완료.\n","'딥러닝' 주제의 위키피디아 문서를 수집합니다...\n","'딥러닝.txt' 파일 저장 완료.\n"]}]},{"cell_type":"code","source":["#@title 3. 도구 2: 실시간 웹 검색 도구\n","web_search_tool = DuckDuckGoSearchRun()"],"metadata":{"id":"dih1wspqaKQn","executionInfo":{"status":"ok","timestamp":1756089038775,"user_tz":-540,"elapsed":9,"user":{"displayName":"Sungmin Han","userId":"16133717747299446002"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["#@title 4. 도구 정의\n","tools = [ai_history_qa_tool, web_search_tool]\n","\n","print(\"에이전트를 위한 도구 2개 정의 완료:\")\n","print(f\"1. {ai_history_qa_tool.name}: {ai_history_qa_tool.description}\")\n","print(f\"2. {web_search_tool.name}: {web_search_tool.description}\")"],"metadata":{"id":"PwIdmHiMPYlp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756089038775,"user_tz":-540,"elapsed":7,"user":{"displayName":"Sungmin Han","userId":"16133717747299446002"}},"outputId":"b814ec47-0bae-46ca-be87-4009fe51b935"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["에이전트를 위한 도구 2개 정의 완료:\n","1. ai_history_qa_tool: '인공지능(AI) 역사', '튜링 테스트', '다트머스 워크숍', '머신러닝', '딥러닝'의 역사나 개념에 대한 질문에 답변할 때 사용합니다.\n","    이 도구는 신뢰할 수 있는 내부 문서 기반으로 답변합니다.\n","2. duckduckgo_search: A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n"]}]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain.agents import AgentExecutor, create_openai_tools_agent\n","\n","# 에이전트를 위한 프롬프트 정의\n","# MessagesPlaceholder는 에이전트의 중간 작업 과정(생각과 관찰)이 저장될 공간이다.\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"당신은 주어진 도구를 사용하여 사용자의 질문에 답변하는 유능한 AI 어시턴트입니다.\"),\n","    (\"user\", \"{input}\"),\n","    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","])\n","\n","# 에이전트 생성\n","# OpenAI의 tool-calling 기능에 최적화된 에이전트를 생성한다.\n","agent = create_openai_tools_agent(llm, tools, prompt)\n","\n","# 에이전트 실행기(Executor) 생성\n","# 에이전트가 결정한 행동을 실제로 실행하는 역할을 담당한다.\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","\n","print(\"ReAct 기반 에이전트 생성 완료.\")"],"metadata":{"id":"UJIt00Jvafmc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756089038784,"user_tz":-540,"elapsed":11,"user":{"displayName":"Sungmin Han","userId":"16133717747299446002"}},"outputId":"adc5ba6e-0878-4cd0-ec88-3991ac1dbf1d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["ReAct 기반 에이전트 생성 완료.\n"]}]},{"cell_type":"code","source":["# 테스트 질문 정의\n","questions = [\n","    # 1번 질문: 내부 백과사전 도구(ai_history_qa_tool)를 사용해야 하는 경우\n","    \"딥러닝과 머신러닝의 개념의 차이점에 대해 우리 백과사전에 있는 내용으로 설명해주세요.\",\n","    # 2번 질문: 실시간 웹 검색 도구(web_search_tool)를 사용해야 하는 경우\n","    \"OpenAI의 가장 최근 마지막으로 발표된 GPT 모델 이름이 뭔가요?\",\n","    # 3번 질문: 두 도구의 정보가 모두 필요할 수 있는 복합적인 경우\n","    \"다트머스 워크숍의 주요 내용과, 그 행사를 주도했던 존 매카시의 최근 근황에 대해 알려주세요.\"\n","]\n","\n","# 각 질문에 대해 에이전트 실행 및 결과 확인\n","for i, question in enumerate(questions):\n","    print(f\"\\n{'='*20} 질문 {i+1} 실행 {'='*20}\")\n","    print(f\"사용자 질문: {question}\")\n","    print(\"-\" * 50)\n","\n","    # 에이전트 실행기를 호출\n","    response = agent_executor.invoke({\"input\": question})\n","\n","    print(\"-\" * 50)\n","    print(f\"최종 답변: {response['output']}\")\n","    print(f\"{'='*55}\")"],"metadata":{"id":"AFY7vcCWsBjK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756089197344,"user_tz":-540,"elapsed":158560,"user":{"displayName":"Sungmin Han","userId":"16133717747299446002"}},"outputId":"e4f3c64d-0eff-45b8-d763-a200c1f85bc2"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================== 질문 1 실행 ====================\n","사용자 질문: 딥러닝과 머신러닝의 개념의 차이점에 대해 우리 백과사전에 있는 내용으로 설명해주세요.\n","--------------------------------------------------\n","\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `ai_history_qa_tool` with `{'query': '딥러닝과 머신러닝의 개념의 차이점에 대해 백과사전 스타일로 설명해 주세요'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m죄송하지만, 제가 가진 정보 내에서는 답변을 찾을 수 없습니다.\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `duckduckgo_search` with `{'query': 'difference between deep learning and machine learning encyclopedia Korean description'}`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3mby CD Yi · 2021 · Cited by 5 — This paper analyzes the feasibility of using machine learning and deep learning methods to forecast the income and employment using the strategic industries. by ML Ali · 2025 · Cited by 11 — Our results indicate that deep learning models, particularly CNN and LSTM , outperform traditional machine learning approaches in cyber threat detection, ... Jul 3, 2025 — ... \"Artificial intelligence\" was defined as a machine learning (ML) or deep learning (DL) tool that identifies patterns resulting in a prediction. Application ... Deep learning, a type of machine learning , utilizes neural networks to simulate human brain function. By employing multiple layers of neural networks, deep ... by L Jiao · 2024 · Cited by 29 — Deep learning relies on learning from extensive data to generate prediction results. This approach may inadvertently capture spurious correlations within ...\u001b[0m\u001b[32;1m\u001b[1;3m요청하신 “우리 백과사전”의 특정 항목을 바로 찾을 수 없어, 일반적인 백과사전 서술 방식으로 딥러닝과 머신러닝의 개념적 차이를 정리해 드립니다.\n","\n","요약\n","- 머신러닝(Machine Learning, ML)은 경험(데이터)으로부터 성능을 향상시키는 알고리즘의 총칭이다.\n","- 딥러닝(Deep Learning, DL)은 머신러닝의 한 분야로, 다층(심층) 인공신경망을 사용해 표현을 자동으로 학습하는 방법이다.\n","\n","정의\n","- 머신러닝: 데이터로부터 규칙이나 모델을 추정해 예측·분류·군집 등 작업을 수행하는 알고리즘 집합. 통계적 방법과 계산적 알고리즘이 결합된 분야로, 지도학습·비지도학습·강화학습 등으로 분류된다.\n","- 딥러닝: 인공신경망(artificial neural networks)을 깊게 쌓아(여러 은닉층) 데이터의 저차원 특징부터 고차원 추상표현까지 계층적으로 학습하는 기법. 특히 이미지, 음성, 자연어처럼 구조화되지 않은(비정형) 데이터에서 강력한 성능을 보인다.\n","\n","핵심 차이점\n","- 원리적 위치: 딥러닝은 머신러닝의 하위집합이다.\n","- 특징(Feature) 처리:\n","  - 전통적 머신러닝: 도메인 지식으로 유용한 특징을 설계(특징공학)한 뒤 모델에 입력.\n","  - 딥러닝: 원시 입력(예: 픽셀, 음성 파형, 텍스트 토큰)에서 유용한 표현을 자동으로 학습.\n","- 모델 구조와 복잡성:\n","  - 머신러닝 알고리즘은 비교적 구조가 단순한(예: 선형 모델, 결정트리, SVM, 그래디언트 부스팅) 경우가 많음.\n","  - 딥러닝은 수백만~수십억 개의 파라미터를 갖는 심층 네트워크를 사용.\n","- 데이터 및 계산 요구:\n","  - 머신러닝: 비교적 적은 데이터로도 잘 작동(특히 좋은 특징이 있을 때).\n","  - 딥러닝: 큰 규모의 데이터와 고성능 하드웨어(GPU/TPU 등)를 요구하는 경향.\n","- 성능 영역:\n","  - 딥러닝은 이미지·음성·자연어 등 비정형 데이터에서 탁월한 성능을 보인다.\n","  - 전통적 머신러닝은 표형(표준화된 구조) 데이터에서 경쟁력 있고 해석이 쉬운 경우가 많음.\n","- 해석 가능성:\n","  - 머신러닝(특히 결정트리, 선형회귀 등)은 비교적 해석이 쉬움.\n","  - 딥러닝 모델은 블랙박스 성격이 강해 해석이 어려움(해석기법별도 존재).\n","\n","대표 알고리즘(예시)\n","- 머신러닝: 선형 회귀, 로지스틱 회귀, 서포트 벡터 머신(SVM), 결정 트리, 랜덤 포레스트, XGBoost(그래디언트 부스팅), K-평균 등.\n","- 딥러닝: 다층 퍼셉트론(MLP), 합성곱 신경망(CNN), 순환신경망(RNN), LSTM/GRU, 트랜스포머(Transformer) 계열 등.\n","\n","장단점 비교\n","- 머신러닝 장점: 적은 데이터로도 학습 가능, 학습·추론 비용이 낮음, 모델 해석성이 상대적으로 높음.\n","- 머신러닝 단점: 좋은 특징 설계가 필요하며 비정형 데이터에서 성능 제약이 있을 수 있음.\n","- 딥러닝 장점: 복잡한 패턴과 고차원 표현을 자동 학습, 비정형 데이터에서 우수한 성능.\n","- 딥러닝 단점: 많은 데이터와 계산 자원 필요, 과적합 위험, 해석 어려움.\n","\n","응용 예\n","- 머신러닝: 고객 이탈 예측, 신용 평가, 장비 고장 예측(표 데이터), 간단한 분류·회귀 문제.\n","- 딥러닝: 이미지 인식·객체 검출, 음성 인식, 기계번역·대화형 AI, 영상 생성(생성 모델), 복잡한 시계열 패턴 학습.\n","\n","언제 어떤 것을 선택할까\n","- 데이터가 적고 도메인 지식으로 좋은 특징을 만들 수 있다면 전통적 머신러닝이 효율적이다.\n","- 데이터가 많고 입력이 비정형(이미지, 음성, 텍스트)이며 높은 성능이 필요하면 딥러닝이 적합하다.\n","- 실무에서는 두 접근을 혼합하거나(특징공학 + 신경망) 전이학습(pretrained models)을 이용해 데이터 요구를 낮추는 방법을 쓰기도 한다.\n","\n","참고적 설명(백과사전 스타일 맺음말)\n","딥러닝은 머신러닝의 한 갈래로, 표현 학습(representation learning)과 심층 신경망의 발전을 통해 과거 어려웠던 여러 문제들을 해결해 왔다. 그러나 본질적으로 두 용어는 포괄 관계에 있으며, 실제 적용에서는 문제 특성·데이터 양·연산 자원·해석 필요성 등을 고려해 적절한 접근법을 선택하는 것이 중요하다.\n","\n","원하시면 우리 백과사전에 있는 특정 문장을 확인하거나, 귀사 백과사전 스타일(문체·길이)에 맞춰 문단을 다듬어 드리겠습니다.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","--------------------------------------------------\n","최종 답변: 요청하신 “우리 백과사전”의 특정 항목을 바로 찾을 수 없어, 일반적인 백과사전 서술 방식으로 딥러닝과 머신러닝의 개념적 차이를 정리해 드립니다.\n","\n","요약\n","- 머신러닝(Machine Learning, ML)은 경험(데이터)으로부터 성능을 향상시키는 알고리즘의 총칭이다.\n","- 딥러닝(Deep Learning, DL)은 머신러닝의 한 분야로, 다층(심층) 인공신경망을 사용해 표현을 자동으로 학습하는 방법이다.\n","\n","정의\n","- 머신러닝: 데이터로부터 규칙이나 모델을 추정해 예측·분류·군집 등 작업을 수행하는 알고리즘 집합. 통계적 방법과 계산적 알고리즘이 결합된 분야로, 지도학습·비지도학습·강화학습 등으로 분류된다.\n","- 딥러닝: 인공신경망(artificial neural networks)을 깊게 쌓아(여러 은닉층) 데이터의 저차원 특징부터 고차원 추상표현까지 계층적으로 학습하는 기법. 특히 이미지, 음성, 자연어처럼 구조화되지 않은(비정형) 데이터에서 강력한 성능을 보인다.\n","\n","핵심 차이점\n","- 원리적 위치: 딥러닝은 머신러닝의 하위집합이다.\n","- 특징(Feature) 처리:\n","  - 전통적 머신러닝: 도메인 지식으로 유용한 특징을 설계(특징공학)한 뒤 모델에 입력.\n","  - 딥러닝: 원시 입력(예: 픽셀, 음성 파형, 텍스트 토큰)에서 유용한 표현을 자동으로 학습.\n","- 모델 구조와 복잡성:\n","  - 머신러닝 알고리즘은 비교적 구조가 단순한(예: 선형 모델, 결정트리, SVM, 그래디언트 부스팅) 경우가 많음.\n","  - 딥러닝은 수백만~수십억 개의 파라미터를 갖는 심층 네트워크를 사용.\n","- 데이터 및 계산 요구:\n","  - 머신러닝: 비교적 적은 데이터로도 잘 작동(특히 좋은 특징이 있을 때).\n","  - 딥러닝: 큰 규모의 데이터와 고성능 하드웨어(GPU/TPU 등)를 요구하는 경향.\n","- 성능 영역:\n","  - 딥러닝은 이미지·음성·자연어 등 비정형 데이터에서 탁월한 성능을 보인다.\n","  - 전통적 머신러닝은 표형(표준화된 구조) 데이터에서 경쟁력 있고 해석이 쉬운 경우가 많음.\n","- 해석 가능성:\n","  - 머신러닝(특히 결정트리, 선형회귀 등)은 비교적 해석이 쉬움.\n","  - 딥러닝 모델은 블랙박스 성격이 강해 해석이 어려움(해석기법별도 존재).\n","\n","대표 알고리즘(예시)\n","- 머신러닝: 선형 회귀, 로지스틱 회귀, 서포트 벡터 머신(SVM), 결정 트리, 랜덤 포레스트, XGBoost(그래디언트 부스팅), K-평균 등.\n","- 딥러닝: 다층 퍼셉트론(MLP), 합성곱 신경망(CNN), 순환신경망(RNN), LSTM/GRU, 트랜스포머(Transformer) 계열 등.\n","\n","장단점 비교\n","- 머신러닝 장점: 적은 데이터로도 학습 가능, 학습·추론 비용이 낮음, 모델 해석성이 상대적으로 높음.\n","- 머신러닝 단점: 좋은 특징 설계가 필요하며 비정형 데이터에서 성능 제약이 있을 수 있음.\n","- 딥러닝 장점: 복잡한 패턴과 고차원 표현을 자동 학습, 비정형 데이터에서 우수한 성능.\n","- 딥러닝 단점: 많은 데이터와 계산 자원 필요, 과적합 위험, 해석 어려움.\n","\n","응용 예\n","- 머신러닝: 고객 이탈 예측, 신용 평가, 장비 고장 예측(표 데이터), 간단한 분류·회귀 문제.\n","- 딥러닝: 이미지 인식·객체 검출, 음성 인식, 기계번역·대화형 AI, 영상 생성(생성 모델), 복잡한 시계열 패턴 학습.\n","\n","언제 어떤 것을 선택할까\n","- 데이터가 적고 도메인 지식으로 좋은 특징을 만들 수 있다면 전통적 머신러닝이 효율적이다.\n","- 데이터가 많고 입력이 비정형(이미지, 음성, 텍스트)이며 높은 성능이 필요하면 딥러닝이 적합하다.\n","- 실무에서는 두 접근을 혼합하거나(특징공학 + 신경망) 전이학습(pretrained models)을 이용해 데이터 요구를 낮추는 방법을 쓰기도 한다.\n","\n","참고적 설명(백과사전 스타일 맺음말)\n","딥러닝은 머신러닝의 한 갈래로, 표현 학습(representation learning)과 심층 신경망의 발전을 통해 과거 어려웠던 여러 문제들을 해결해 왔다. 그러나 본질적으로 두 용어는 포괄 관계에 있으며, 실제 적용에서는 문제 특성·데이터 양·연산 자원·해석 필요성 등을 고려해 적절한 접근법을 선택하는 것이 중요하다.\n","\n","원하시면 우리 백과사전에 있는 특정 문장을 확인하거나, 귀사 백과사전 스타일(문체·길이)에 맞춰 문단을 다듬어 드리겠습니다.\n","=======================================================\n","\n","==================== 질문 2 실행 ====================\n","사용자 질문: OpenAI의 가장 최근 마지막으로 발표된 GPT 모델 이름이 뭔가요?\n","--------------------------------------------------\n","\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `duckduckgo_search` with `{'query': \"OpenAI 최근 발표한 GPT 모델 이름 2025 'GPT' 발표 최신 모델 이름\"}`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3mOpenAI, Inc. is an American artificial intelligence (AI) organization headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence … 5 days ago - GPT (Generative pre-trained transformer)는 미국의 인공지능 단체 오픈AI가 2018년 선보인 대형 언어 모델 (LLM)의 계열이며 GPT 모델들은 레이블링되지 않은 대량의 텍스트 데이터셋으로 미리 훈련되고 인간과 같은 문자를 생성할 수 있는 ... 1 week ago - 챗GPT(ChatGPT)는 오픈AI가 개발하고 2022년 11월 30일에 출시한 생성형 인공지능 챗봇이다. GPT -4o와 같은 대형 언어 모델 (LLM)과 기타 멀티모달 모델을 사용하여 텍스트, 음성 및 이미지로 사람과 유사한 응답을 생성한다. Apr 16, 2025 · OpenAI o3 is our most powerful reasoning model that pushes the frontier across coding, math, science, visual perception, and more. It sets a new SOTA on benchmarks … Aug 7, 2025 · OpenAI on Thursday announced GPT-5, its latest and most advanced large-scale artificial intelligence model. The company is making GPT-5 available to everyone, including its …\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `duckduckgo_search` with `{'query': \"OpenAI announced GPT-5 Aug 7 2025 'GPT-5' announcement OpenAI 2025\"}`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3mOpenAI, Inc. is an American artificial intelligence (AI) organization headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence … Apr 16, 2025 · OpenAI o3 is our most powerful reasoning model that pushes the frontier across coding, math, science, visual perception, and more. It sets a new SOTA on benchmarks … Aug 7, 2025 · OpenAI on Thursday announced GPT-5, its latest and most advanced large-scale artificial intelligence model. The company is making GPT-5 available to everyone, including its … Aug 7, 2025 · Discover how a specialized AI model, GPT-4b micro, helped OpenAI and Retro Bio engineer more effective proteins for stem cell therapy and longevity research. We are … Aug 7, 2025 · OpenAI hopes its fastest, smartest model yet will help it fend off rising competition from Google, Meta, Anthropic, and Chinese startups.\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `duckduckgo_search` with `{'query': \"OpenAI GPT-5 announced Aug 7 2025 press release 'GPT-5' OpenAI blog Aug 2025 'GPT-5' announcement site:openai.com\"}`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3mAs part of Thursday’s launch, OpenAI announced two new model variants: a lightweight GPT - 5 -mini and an even faster, cheaper, GPT - 5 -nano (which is ... OpenAI has officially announced GPT - 5 , its latest frontier model to power ChatGPT. The announcement follows the release of two open weight models ... OpenAI today introduced GPT - 5 , which the company says brings a \"significant leap\" in intelligence and fewer hallucinations. It may be a several more months before OpenAI officially announces the release date for GPT - 5 , but we will likely get more leaks and info as we get ... For months, OpenAI Chief Executive Officer Sam Altman has been hyping up the capabilities of GPT - 5 , setting up the launch as a seminal moment for the ...\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `duckduckgo_search` with `{'query': 'site:openai.com \"GPT-5\" OpenAI blog GPT-5 announcement Aug 2025'}`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3mAug 7, 2025 · We’re releasing GPT ‑ 5 in three sizes in the API— gpt - 5 , gpt -5-mini, and gpt-5-nano —to give developers more flexibility to trade off performance, cost, and latency. Aug 7, 2025 · For the most challenging, complex tasks, we are also releasing GPT ‑ 5 pro, replacing OpenAI o3‑pro, a variant of GPT ‑ 5 that thinks for ever longer, using scaled but efficient parallel test-time compute, to provide the highest quality and most comprehensive answers. Aug 7, 2025 · See how a group of leading developers use GPT-5 for the first time. GPT - 5 brings together all of our research breakthroughs into a unified experience for our smartest, most reliable AI system yet. Check out our blog announcement here. Aug 7, 2025 · I am optimistic that GPT - 5 is going to be an improvement, many seem to say so already, but by hard-removing access to prior versions for paid users, 100% of the positivity of the update has been erased.\u001b[0m\u001b[32;1m\u001b[1;3m가장 최근에 발표된 모델 이름은 GPT-5입니다. (OpenAI가 2025년 8월 7일 공개했으며, gpt-5, gpt-5-mini, gpt-5-nano 및 고성능 버전인 GPT‑5 Pro 같은 변형들이 함께 발표되었습니다.) 더 자세한 정보나 공식 출처 링크 원하시면 알려주세요.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","--------------------------------------------------\n","최종 답변: 가장 최근에 발표된 모델 이름은 GPT-5입니다. (OpenAI가 2025년 8월 7일 공개했으며, gpt-5, gpt-5-mini, gpt-5-nano 및 고성능 버전인 GPT‑5 Pro 같은 변형들이 함께 발표되었습니다.) 더 자세한 정보나 공식 출처 링크 원하시면 알려주세요.\n","=======================================================\n","\n","==================== 질문 3 실행 ====================\n","사용자 질문: 다트머스 워크숍의 주요 내용과, 그 행사를 주도했던 존 매카시의 최근 근황에 대해 알려주세요.\n","--------------------------------------------------\n","\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `ai_history_qa_tool` with `{'query': \"Dartmouth Workshop 1956 주요 내용 역사 개요 중요 성과 참석자 조직자 목표 'Dartmouth Conference' 'Dartmouth Summer Research Project on Artificial Intelligence'\"}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m개요\n","- 1956년 다트머스에서 열린 다트머스 컨퍼런스는 인공지능(AI)의 탄생을 알린 사건으로 묘사됩니다. [출처: 다트머스 컨퍼런스 1956년: AI의 탄생]\n","\n","조직자(개최자)\n","- 마빈 민스키, 존 매카시, IBM의 수석 과학자 클로드 섀넌, 네이선 로체스터가 개최했습니다. [출처: 다트머스 컨퍼런스 1956년: AI의 탄생]\n","\n","참석자(예시)\n","- 레이 솔로모노프, 올리버 셀프리지, 트렌처드 모어, 아서 새뮤얼(문헌에는 Arthur Smuel로 표기됨), 앨런 뉴얼, 허버트 A. 사이먼 등이 참석했습니다. 이들은 이후 수십 년간 AI 연구에서 중요한 프로그램들을 만든 사람들입니다. [출처: 다트머스 컨퍼런스 1956년: AI의 탄생]\n","\n","목표 및 주요 제안\n","- 제안서에는 “학습의 모든 면 또는 지능의 다른 모든 특성로 기계를 정밀하게 기술할 수 있고 이를 시물레이션 할 수 있다”는 주장이 포함되어 있었습니다. 즉, 학습과 지능의 여러 측면을 기계로 기술·시뮬레이션하려는 목표를 제시했습니다. [출처: 다트머스 컨퍼런스 1956년: AI의 탄생]\n","- 회의에서 매카시는 이 연구영역을 가리키는 이름으로 \"Artificial Intelligence\"를 사용하도록 설득했습니다. [출처: 다트머스 컨퍼런스 1956년: AI의 탄생]\n","\n","주요 내용·성과\n","- 앨런 뉴얼과 허버트 사이먼은 \"논리 이론\"(문헌 표현)을 소개했습니다. [출처: 다트머스 컨퍼런스 1956년: AI의 탄생]\n","- 컨퍼런스 이후의 초기 AI 연구 성과로는 대수학 문제 해결, 기하학 정리 증명, 영어 학습 등을 수행한 프로그램들이 개발되어 많은 사람들을 놀라게 했습니다. [출처: 다트머스 컨퍼런스 1956년: AI의 탄생 / 황금기(1956~1974년)]\n","\n","역사적 의의\n","- 1956년 다트머스 컨퍼런스는 'AI'라는 이름의 채택, 연구 목표 설정, 초기 성공과 이를 이룬 연구자들의 등장을 포함하는 순간으로서 넓은 의미의 인공지능 탄생으로 평가됩니다. 또한 이후(1956–1974년) 연구 낙관론과 ARPA 등 기관의 자금 투입으로 이어져 AI 황금기가 시작되었습니다. [출처: 다트머스 컨퍼런스 1956년: AI의 탄생 / 황금기(1956~1974년)]\n","\n","출처\n","- [출처: 다트머스 컨퍼런스 1956년: AI의 탄생]\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `duckduckgo_search` with `{'query': 'John McCarthy death 2011 obituary date cause Stanford 2011 John McCarthy AI obituary'}`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3mMay 30, 2025 — DARPA made similar grants to Newell and Simon's program at Carnegie Mellon University and to Stanford University's AI Lab, founded by John McCarthy in 1963. Choose wisely! Browse Obituaries and Death Records in Garland, Texas This page shows only the 20 most recent obituaries in Garland, Texas. Aug 15, 2025 — John McCarthy ; Born: September 4, 1927, Boston, Massachusetts, U.S. ; Died: October 24, 2011, Stanford, California (aged 84) ; Awards And Honors: National Medal ... Sep 25, 2024 — John McCarthy died on October 24, 2011 from heart disease complications at the age of 84, only a few months after recording this oral history. In 1964, an American computer scientist named John McCarthy set up a research centre at California’s Stanford University to explore an exciting new ...\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `ai_history_qa_tool` with `{'query': \"Dartmouth Workshop 1956 attendees list organizers John McCarthy Marvin Minsky Nathaniel Rochester Claude Shannon Allen Newell Herbert Simon Arthur Samuel what happened outcomes 'Dartmouth Summer Research Project on Artificial Intelligence' summary\"}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m요청하신 다트머스 워크숍(1956) 요약 — 출처에 근거한 정보만 제시합니다.\n","\n","- 조직자(주최): 마빈 민스키, 존 매카시, 클로드 섀넌(IBM 수석 과학자), 네이선 로체스터.  \n","- 참가자(문맥에 언급된 인물): 레이 솔로모노프, 올리버 셀프리지, 트렌처드 모어, 아서 새뮤얼, 앨런 뉴얼, 허버트 A. 사이먼.  \n","- 주요 사건 및 결과 요약:\n","  - 뉴얼과 사이먼이 \"논리 이론\"을 소개함.  \n","  - 존 매카시가 그들의 연구를 가리키는 이름으로 \"Artificial Intelligence\"라는 명칭을 받아들이도록 설득함.  \n","  - 이 회의는 \"AI\"라는 이름의 확립, 연구 목표 설정, 초기 성공 사례들(첫번째 성공들)과 함께 넓은 의미의 인공지능의 탄생을 알린 순간으로 평가됨.  \n","  - 이후(1956~1974)의 황금기 동안 AI 분야에서 대수 문제 해결, 기하 정리 증명, 영어 학습 등을 수행하는 프로그램들이 등장했고, 낙관적 기대와 함께 ARPA 등의 기관이 자금을 지원함.\n","\n","[출처: 다트머스 컨퍼런스 1956년: AI의 탄생]\u001b[0m\u001b[32;1m\u001b[1;3m요약해서 답드리겠습니다.\n","\n","1) 다트머스 워크숍(1956)의 주요 내용\n","- 정식 명칭: \"Dartmouth Summer Research Project on Artificial Intelligence\" (1956년 여름).\n","- 조직자(주최): 존 매카시(John McCarthy), 마빈 민스키(Marvin Minsky), 네이선 로체스터(Nathaniel Rochester), 클로드 섀넌(Claude Shannon) 등.\n","- 참석자(주요 인물): 앨런 뉴얼(Allen Newell), 허버트 사이먼(Herbert A. Simon), 아서 새뮤얼(Arthur Samuel), 레이 솔로모노프(Ray Solomonoff), 올리버 셀프리지 등 초기 AI 연구자들이 참여했습니다.\n","- 목표와 논점: 기호적 추론, 기계학습, 문제해결, 언어 이해 등 기계가 “지능”으로 보일 수 있는 여러 능력을 연구하자는 공동의 연구 계획 수립. 회의 제안서에서 “Artificial Intelligence”라는 용어를 사용·정착시키는 계기가 되었습니다.\n","- 성과와 의의: 인공지능을 독립 학문 분야로 공식화한 사건으로 평가됩니다. 이후 Logic Theorist(뉴얼·사이먼), 체커 학습 프로그램(아서 새뮤얼) 등 초기 성과들이 이어졌고, 연구 자금(예: ARPA 등)과 연구 커뮤니티 형성을 촉진해 AI 연구의 기반을 마련했습니다.\n","\n","2) 행사 주도자 중 한 명인 존 매카시의 최근 근황\n","- 현재 상태: 존 매카시는 2011년 10월 24일 캘리포니아 스탠퍼드에서 심장 질환 합병증으로 사망했습니다(1927년 9월 4일 출생, 향년 84세). 따라서 “최근 근황”은 더 이상 활동 중이 아님을 알려드립니다.\n","- 주요 업적(간단히): Lisp 언어(1958년)를 고안, 스탠퍼드 AI 연구소(SAIL) 설립(1960년대), “Artificial Intelligence” 용어 정착에 기여, 형식적 추론·비상식적 추론 연구(예: circumscription) 등. 1971년 튜링상 수상 등 학계 주요 수상을 받았습니다.\n","- 말년 활동: 말년에도 AI 관련 회고·구술녹음(oral history)·저술 등으로 자신의 연구와 생각을 남겼고, 여러 회고·자료가 아카이브에 남아 있습니다.\n","\n","원하시면 다트머스 회의의 원문 제안서 핵심 문구, 참석자 목록 및 각 참석자가 발표·제시한 구체적 연구 주제, 혹은 존 매카시의 대표 논문(예: Lisp 관련, 비상식 추론 관련) 목록을 추가로 제공해 드리겠습니다.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","--------------------------------------------------\n","최종 답변: 요약해서 답드리겠습니다.\n","\n","1) 다트머스 워크숍(1956)의 주요 내용\n","- 정식 명칭: \"Dartmouth Summer Research Project on Artificial Intelligence\" (1956년 여름).\n","- 조직자(주최): 존 매카시(John McCarthy), 마빈 민스키(Marvin Minsky), 네이선 로체스터(Nathaniel Rochester), 클로드 섀넌(Claude Shannon) 등.\n","- 참석자(주요 인물): 앨런 뉴얼(Allen Newell), 허버트 사이먼(Herbert A. Simon), 아서 새뮤얼(Arthur Samuel), 레이 솔로모노프(Ray Solomonoff), 올리버 셀프리지 등 초기 AI 연구자들이 참여했습니다.\n","- 목표와 논점: 기호적 추론, 기계학습, 문제해결, 언어 이해 등 기계가 “지능”으로 보일 수 있는 여러 능력을 연구하자는 공동의 연구 계획 수립. 회의 제안서에서 “Artificial Intelligence”라는 용어를 사용·정착시키는 계기가 되었습니다.\n","- 성과와 의의: 인공지능을 독립 학문 분야로 공식화한 사건으로 평가됩니다. 이후 Logic Theorist(뉴얼·사이먼), 체커 학습 프로그램(아서 새뮤얼) 등 초기 성과들이 이어졌고, 연구 자금(예: ARPA 등)과 연구 커뮤니티 형성을 촉진해 AI 연구의 기반을 마련했습니다.\n","\n","2) 행사 주도자 중 한 명인 존 매카시의 최근 근황\n","- 현재 상태: 존 매카시는 2011년 10월 24일 캘리포니아 스탠퍼드에서 심장 질환 합병증으로 사망했습니다(1927년 9월 4일 출생, 향년 84세). 따라서 “최근 근황”은 더 이상 활동 중이 아님을 알려드립니다.\n","- 주요 업적(간단히): Lisp 언어(1958년)를 고안, 스탠퍼드 AI 연구소(SAIL) 설립(1960년대), “Artificial Intelligence” 용어 정착에 기여, 형식적 추론·비상식적 추론 연구(예: circumscription) 등. 1971년 튜링상 수상 등 학계 주요 수상을 받았습니다.\n","- 말년 활동: 말년에도 AI 관련 회고·구술녹음(oral history)·저술 등으로 자신의 연구와 생각을 남겼고, 여러 회고·자료가 아카이브에 남아 있습니다.\n","\n","원하시면 다트머스 회의의 원문 제안서 핵심 문구, 참석자 목록 및 각 참석자가 발표·제시한 구체적 연구 주제, 혹은 존 매카시의 대표 논문(예: Lisp 관련, 비상식 추론 관련) 목록을 추가로 제공해 드리겠습니다.\n","=======================================================\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NeJkFq96tCvm","executionInfo":{"status":"ok","timestamp":1756089197346,"user_tz":-540,"elapsed":25,"user":{"displayName":"Sungmin Han","userId":"16133717747299446002"}}},"execution_count":17,"outputs":[]}]}