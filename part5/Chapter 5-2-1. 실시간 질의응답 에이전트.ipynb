{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h8oLa_dMSJHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c6d611-03ef-4203-dbd2-3aee99fa610b",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langchain-community (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langchain-community (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "google-adk 1.11.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "google-adk 1.11.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title 1. 의존성 패키지 설치\n",
        "!pip install -q langchain langchain-chroma langchain-openai wikipedia ddgs\n",
        "\n",
        "# langchain-community 최신 버전 설치 (ddgs 패키지 지원을 위하여)\n",
        "!pip install -q --force-reinstall git+https://github.com/langchain-ai/langchain-community.git@main#subdirectory=libs/community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv16A2XN8k7j",
        "outputId": "5a388f7b-dfff-4ab9-8403-31a5bd15d55b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain-community\n",
            "Version: 0.3.27\n",
            "Summary: Community contributed LangChain integrations.\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: aiohttp, dataclasses-json, httpx-sse, langchain, langchain-core, langsmith, numpy, pydantic-settings, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n",
            "Name: langchain-community\n",
            "Version: 0.3.27\n",
            "Summary: Community contributed LangChain integrations.\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: aiohttp, dataclasses-json, httpx-sse, langchain, langchain-core, langsmith, numpy, pydantic-settings, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain.tools import tool\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from google.colab import userdata\n",
        "import wikipedia"
      ],
      "metadata": {
        "id": "ZnExs3saU9xP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "uqmwQ7ixaFDm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. 도구 1: AI 역사 백과사전 Q&A 도구\n",
        "\n",
        "# 한국어 위키피디아로 언어 설정\n",
        "wikipedia.set_lang(\"ko\")\n",
        "\n",
        "# 지식 베이스로 사용할 문서 주제 목록\n",
        "topics = [\"머신러닝\", \"딥러닝\", \"인공지능\"]\n",
        "\n",
        "# 수집된 내용을 저장할 디렉토리 생성\n",
        "os.makedirs(\"ai_wiki_docs\", exist_ok=True)\n",
        "\n",
        "for topic in topics:\n",
        "    print(f\"'{topic}' 주제의 위키피디아 문서를 수집합니다...\")\n",
        "    try:\n",
        "        # 위키피디아에서 해당 주제의 페이지 객체를 가져옴\n",
        "        page = wikipedia.page(topic, auto_suggest=False)\n",
        "\n",
        "        # 페이지의 전체 텍스트 내용을 파일로 저장\n",
        "        with open(f\"ai_wiki_docs/{topic}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(page.content)\n",
        "        print(f\"'{topic}.txt' 파일 저장 완료.\")\n",
        "    except wikipedia.exceptions.PageError:\n",
        "        print(f\"'{topic}'에 대한 위키피디아 페이지를 찾을 수 없습니다.\")\n",
        "    except wikipedia.exceptions.DisambiguationError as e:\n",
        "        print(f\"'{topic}'에 대한 여러 페이지가 있어 명확한 지정이 필요합니다: {e.options}\")\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-5-mini\",\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")\n",
        "loader = DirectoryLoader(\n",
        "    \"./ai_wiki_docs\",\n",
        "    glob=\"*.txt\",\n",
        "    loader_cls=TextLoader,\n",
        "    loader_kwargs={\"encoding\": \"utf-8\"}\n",
        ")\n",
        "documents = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(documents)\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY),\n",
        "    persist_directory=\"./chroma_db_ai_project\"\n",
        ")\n",
        "retriever = vectorstore.as_retriever()\n",
        "rephrasing_prompt = ChatPromptTemplate.from_messages([\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"user\", \"주어진 대화 기록을 바탕으로, 후속 질문을 검색에 사용할 수 있는 독립적인 질문으로 바꾸어주세요.\"),\n",
        "])\n",
        "\n",
        "history_aware_retriever = create_history_aware_retriever(llm, retriever, rephrasing_prompt)\n",
        "answer_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"당신은 AI 전문가입니다. 당신의 임무는 오직 주어진 문맥(context) 정보만을 사용하여 사용자의 질문에 답변하는 것입니다.\n",
        "\n",
        "- 답변의 근거가 된 출처 문서의 이름을 항상 명시해야 합니다. (예: [출처: 인공지능.txt])\n",
        "\n",
        "- 문맥 정보에 질문에 대한 답변이 포함되어 있지 않다면, 당신의 기존 지식을 활용하지 말고 반드시 \"죄송하지만, 제가 가진 정보 내에서는 답변을 찾을 수 없습니다.\"라고만 답변하세요.\n",
        "\n",
        "- 절대 외부 정보를 사용하거나 답변을 지어내지 마세요.\"\"\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"system\", \"--- 검색된 문맥 ---\\n{context}\\n--- 문맥 끝 ---\"),\n",
        "])\n",
        "document_chain = create_stuff_documents_chain(llm, answer_prompt)\n",
        "conversational_rag_chain = create_retrieval_chain(history_aware_retriever, document_chain)\n",
        "\n",
        "\n",
        "@tool\n",
        "def ai_history_qa_tool(query: str) -> str:\n",
        "    \"\"\"'인공지능(AI) 역사', '튜링 테스트', '다트머스 워크숍', '머신러닝', '딥러닝'의 역사나 개념에 대한 질문에 답변할 때 사용합니다.\n",
        "    이 도구는 신뢰할 수 있는 내부 문서 기반으로 답변합니다.\"\"\"\n",
        "    # 대화형 체인이므로, 빈 대화 기록과 함께 호출\n",
        "    response = conversational_rag_chain.invoke({\n",
        "        \"chat_history\": [],\n",
        "        \"input\": query\n",
        "    })\n",
        "    return response[\"answer\"]"
      ],
      "metadata": {
        "id": "7yHFmf8wU_cR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987aed78-c616-4150-d8f3-9bed0d829ca3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'기계_학습' 주제의 위키피디아 문서를 수집합니다...\n",
            "'기계_학습.txt' 파일 저장 완료.\n",
            "'딥_러닝' 주제의 위키피디아 문서를 수집합니다...\n",
            "'딥_러닝.txt' 파일 저장 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. 도구 2: 실시간 웹 검색 도구\n",
        "web_search_tool = DuckDuckGoSearchRun()"
      ],
      "metadata": {
        "id": "dih1wspqaKQn",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. 도구 정의\n",
        "tools = [ai_history_qa_tool, web_search_tool]\n",
        "\n",
        "print(\"에이전트를 위한 도구 2개 정의 완료:\")\n",
        "print(f\"1. {ai_history_qa_tool.name}: {ai_history_qa_tool.description}\")\n",
        "print(f\"2. {web_search_tool.name}: {web_search_tool.description}\")"
      ],
      "metadata": {
        "id": "PwIdmHiMPYlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee51347-a557-408c-c17d-2a72e2ba2a9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에이전트를 위한 도구 2개 정의 완료:\n",
            "1. ai_history_qa_tool: '인공지능(AI) 역사', '튜링 테스트', '다트머스 워크숍', '머신러닝', '딥러닝'의 역사나 개념에 대한 질문에 답변할 때 사용합니다.\n",
            "    이 도구는 신뢰할 수 있는 내부 문서 기반으로 답변합니다.\n",
            "2. duckduckgo_search: A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "에이전트를 위한 도구 2개 정의 완료:\n",
            "1. ai_history_qa_tool: '인공지능(AI) 역사', '튜링 테스트', '다트머스 워크숍', '머신러닝', '딥러닝'의 역사나 개념에 대한 질문에 답변할 때 사용합니다.\n",
            "    이 도구는 신뢰할 수 있는 내부 문서 기반으로 답변합니다.\n",
            "2. duckduckgo_search: A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "\n",
        "# 에이전트를 위한 프롬프트 정의\n",
        "# MessagesPlaceholder는 에이전트의 중간 작업 과정(생각과 관찰)이 저장될 공간이다.\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"당신은 주어진 도구를 사용하여 사용자의 질문에 답변하는 유능한 AI 어시턴트입니다.\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "# 에이전트 생성\n",
        "# OpenAI의 tool-calling 기능에 최적화된 에이전트를 생성한다.\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "\n",
        "# 에이전트 실행기(Executor) 생성\n",
        "# 에이전트가 결정한 행동을 실제로 실행하는 역할을 담당한다.\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "print(\"ReAct 기반 에이전트 생성 완료.\")"
      ],
      "metadata": {
        "id": "UJIt00Jvafmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c75794-221c-4b2a-a362-1f0943da6d87"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReAct 기반 에이전트 생성 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 질문 정의\n",
        "questions = [\n",
        "    # 1번 질문: 내부 백과사전 도구(ai_history_qa_tool)를 사용해야 하는 경우\n",
        "    \"딥러닝과 머신러닝의 개념의 차이점에 대해 우리 백과사전에 있는 내용으로 설명해주세요.\",\n",
        "    # 2번 질문: 실시간 웹 검색 도구(web_search_tool)를 사용해야 하는 경우\n",
        "    \"OpenAI의 가장 최근 마지막으로 발표된 GPT 모델 이름이 뭔가요?\",\n",
        "    # 3번 질문: 두 도구의 정보가 모두 필요할 수 있는 복합적인 경우\n",
        "    \"다트머스 워크숍의 주요 내용과, 그 행사를 주도했던 존 매카시의 최근 근황에 대해 알려주세요.\"\n",
        "]\n",
        "\n",
        "# 각 질문에 대해 에이전트 실행 및 결과 확인\n",
        "for i, question in enumerate(questions):\n",
        "    print(f\"\\n{'='*20} 질문 {i+1} 실행 {'='*20}\")\n",
        "    print(f\"사용자 질문: {question}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # 에이전트 실행기를 호출\n",
        "    response = agent_executor.invoke({\"input\": question})\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"최종 답변: {response['output']}\")\n",
        "    print(f\"{'='*55}\")"
      ],
      "metadata": {
        "id": "AFY7vcCWsBjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a877d7df-a83e-4f57-aa78-3c0bd94cf383"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== 질문 1 실행 ====================\n",
            "사용자 질문: 딥러닝과 머신러닝의 개념의 차이점에 대해 우리 백과사전에 있는 내용으로 설명해주세요.\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ai_history_qa_tool` with `{'query': '딥러닝과 머신러닝의 개념의 차이점'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m문맥에 근거한 요약 — 딥러닝과 머신러닝의 차이점\n",
            "\n",
            "- 범위\n",
            "  - 딥러닝은 기계학습(머신러닝)의 한 분야로 설명되어 있음. 즉 딥러닝 ⊂ 머신러닝.  \n",
            "    (문맥: \"큰 틀에서 ... 기계학습의 한 분야라고 이야기할 수 있다.\")\n",
            "- 핵심 개념(딥러닝)\n",
            "  - 여러 '비선형 변환기법'의 조합을 통해 높은 수준의 추상화(표현)를 학습하려는 기계학습 알고리즘의 집합임.  \n",
            "  - 데이터로부터 좋은 표현(representation)을 자동으로 만들고 이를 학습에 적용하는 것에 중점이 있음.  \n",
            "  - 대표적 기법으로 deep neural networks, convolutional deep neural networks, deep belief networks 등이 언급됨.\n",
            "- 적용 및 특징\n",
            "  - 대량의 데이터와 복잡한 자료에서 핵심 내용을 추출하는 데 쓰이며(문맥: \"다량의 데이터\"), 컴퓨터 비전, 음성인식, 자연어 처리 등 최첨단 분야에 적용된다고 설명됨.\n",
            "  - 2012년 대규모 DNN을 이용한 유튜브 비디오의 고양이 인식 사례 등 실용적 성과가 예로 제시됨.\n",
            "\n",
            "참고: 문맥에서는 머신러닝의 포괄적 정의는 상세히 제공하고 있지 않으나, 딥러닝이 그 하위 분야로서 여러 비선형 변환을 통한 고수준 표현 학습에 초점을 둔다는 점이 명확히 서술되어 있습니다.\n",
            "\n",
            "[출처: 심층학습.txt]\u001b[0m\u001b[32;1m\u001b[1;3m요청하신 대로 우리 백과사전 내용을 바탕으로 요약해 드립니다. (출처: 심층학습.txt)\n",
            "\n",
            "- 범위\n",
            "  - 머신러닝(기계학습)은 데이터로부터 학습하는 알고리즘 전반을 가리키는 포괄적 분야입니다.\n",
            "  - 딥러닝은 머신러닝의 한 하위 분야로, 딥러닝 ⊂ 머신러닝으로 설명됩니다.\n",
            "\n",
            "- 핵심 개념의 차이\n",
            "  - 머신러닝: 다양한 통계적·알고리즘적 기법(예: 회귀, SVM, 결정트리, 앙상블 등)을 통해 데이터를 모델링하고 예측·분류 등을 수행하는 넓은 범위의 기술 집합을 의미합니다. (백과사전에는 머신러닝의 포괄적 정의는 상세히 다루어지지 않음)\n",
            "  - 딥러닝: 여러 층의 비선형 변환을 연속적으로 쌓아 높은 수준의 표현(representation)을 자동으로 학습하는 알고리즘 집합입니다. 즉, 데이터로부터 유용한 표현을 자동으로 만들어 내는 데 중점을 둡니다.\n",
            "\n",
            "- 대표 기법\n",
            "  - 머신러닝: 전통적 알고리즘(위에 언급한 여러 방법).\n",
            "  - 딥러닝: 심층 신경망(Deep Neural Networks), 합성곱 신경망(CNN), 심층 신뢰망(Deep Belief Networks) 등.\n",
            "\n",
            "- 특징 및 적용\n",
            "  - 딥러닝은 대량의 데이터와 복잡한 입력(이미지, 음성, 자연어 등)에서 유용한 표현을 추출하는 데 강점이 있으며, 컴퓨터 비전·음성인식·자연어처리 등 최첨단 분야에서 널리 쓰입니다.\n",
            "  - 백과사전은 2012년 대규모 DNN으로 유튜브 영상에서 ‘고양이’를 인식한 사례처럼 실용적 성과가 있었음을 예로 들고 있습니다.\n",
            "\n",
            "요약: 백과사전에 따르면 딥러닝은 여러 비선형 변환을 통해 높은 수준의 표현을 자동으로 학습하는, 머신러닝의 하위 분야이며 특히 대규모 데이터와 복잡한 문제에서 강력한 성능을 보인다는 점이 주요 차이입니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "--------------------------------------------------\n",
            "최종 답변: 요청하신 대로 우리 백과사전 내용을 바탕으로 요약해 드립니다. (출처: 심층학습.txt)\n",
            "\n",
            "- 범위\n",
            "  - 머신러닝(기계학습)은 데이터로부터 학습하는 알고리즘 전반을 가리키는 포괄적 분야입니다.\n",
            "  - 딥러닝은 머신러닝의 한 하위 분야로, 딥러닝 ⊂ 머신러닝으로 설명됩니다.\n",
            "\n",
            "- 핵심 개념의 차이\n",
            "  - 머신러닝: 다양한 통계적·알고리즘적 기법(예: 회귀, SVM, 결정트리, 앙상블 등)을 통해 데이터를 모델링하고 예측·분류 등을 수행하는 넓은 범위의 기술 집합을 의미합니다. (백과사전에는 머신러닝의 포괄적 정의는 상세히 다루어지지 않음)\n",
            "  - 딥러닝: 여러 층의 비선형 변환을 연속적으로 쌓아 높은 수준의 표현(representation)을 자동으로 학습하는 알고리즘 집합입니다. 즉, 데이터로부터 유용한 표현을 자동으로 만들어 내는 데 중점을 둡니다.\n",
            "\n",
            "- 대표 기법\n",
            "  - 머신러닝: 전통적 알고리즘(위에 언급한 여러 방법).\n",
            "  - 딥러닝: 심층 신경망(Deep Neural Networks), 합성곱 신경망(CNN), 심층 신뢰망(Deep Belief Networks) 등.\n",
            "\n",
            "- 특징 및 적용\n",
            "  - 딥러닝은 대량의 데이터와 복잡한 입력(이미지, 음성, 자연어 등)에서 유용한 표현을 추출하는 데 강점이 있으며, 컴퓨터 비전·음성인식·자연어처리 등 최첨단 분야에서 널리 쓰입니다.\n",
            "  - 백과사전은 2012년 대규모 DNN으로 유튜브 영상에서 ‘고양이’를 인식한 사례처럼 실용적 성과가 있었음을 예로 들고 있습니다.\n",
            "\n",
            "요약: 백과사전에 따르면 딥러닝은 여러 비선형 변환을 통해 높은 수준의 표현을 자동으로 학습하는, 머신러닝의 하위 분야이며 특히 대규모 데이터와 복잡한 문제에서 강력한 성능을 보인다는 점이 주요 차이입니다.\n",
            "=======================================================\n",
            "\n",
            "==================== 질문 2 실행 ====================\n",
            "사용자 질문: OpenAI의 가장 최근 마지막으로 발표된 GPT 모델 이름이 뭔가요?\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `duckduckgo_search` with `{'query': 'OpenAI latest GPT model announced 2025 \"GPT\" model name announced OpenAI 2025 GPT-4o GPT-5 announcement'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mAug 7, 2025 · OpenAI on Thursday announced GPT-5 , its latest and most advanced AI model . The company said the model is smarter, faster and more useful, particularly across domains like writing, coding and ... Aug 7, 2025 · OpenAI has launched GPT - 5 , a new flagship AI model that will power the company’s next generation of ChatGPT. GPT - 5 , which was released Thursday, is OpenAI ’s first “unified” AI model and... 3 weeks ago - OpenAI ' s GPT - 5 , the latest installment of the AI technology that powered the ChatGPT juggernaut in 2022, is set for an imminent release, and users will scrutinize if the step up from GPT -4 is on par with the research lab's previous improvements. 3 weeks ago - OpenAI released GPT - 5 on Thursday to both free users of ChatGPT and paying subscribers. 3 weeks ago - Dropping soon. pic.twitter.com/WSuOn3qE6yAugust 7, 2025 · OpenAI just tweeted a GPT - 5 teaser, and as the name would suggest it doesn't give us any real insight other than the fact that it's likely going to replace GPT - 4o .\u001b[0m\u001b[32;1m\u001b[1;3mOpenAI가 가장 최근에 발표한 GPT 모델 이름은 \"GPT-5\"입니다. (발표일: 2025년 8월 7일 기준) 원하시면 관련 기사 링크나 더 자세한 정보 찾아드릴게요.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "--------------------------------------------------\n",
            "최종 답변: OpenAI가 가장 최근에 발표한 GPT 모델 이름은 \"GPT-5\"입니다. (발표일: 2025년 8월 7일 기준) 원하시면 관련 기사 링크나 더 자세한 정보 찾아드릴게요.\n",
            "=======================================================\n",
            "\n",
            "==================== 질문 3 실행 ====================\n",
            "사용자 질문: 다트머스 워크숍의 주요 내용과, 그 행사를 주도했던 존 매카시의 최근 근황에 대해 알려주세요.\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ai_history_qa_tool` with `{'query': '다트머스 워크숍의 주요 내용과 그 행사를 주도했던 존 매카시(John McCarthy)의 최근 근황에 대해 알려줘'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m다트머스 워크숍(1956)의 주요 내용 요약:\n",
            "- 주최자: 마빈 민스키, 존 매카시, 클로드 섀넌, 네이선 로체스터.  \n",
            "- 제안 핵심: “학습의 모든 면 또는 지능의 다른 모든 특성을 기계로 정밀하게 기술하고 시뮬레이션할 수 있다”는 주장 제기.  \n",
            "- 주요 참가자: 레이 솔로모노프, 올리버 셀프리지, 트렌처드 모어, 아서 새뮤얼, 앨런 뉴얼, 허버트 사이먼 등.  \n",
            "- 성과와 의의: 뉴얼과 사이먼이 논리 이론(logic theory)을 소개했고, 매카시는 그들의 연구를 가리키는 명칭으로 “Artificial Intelligence”라는 용어를 채택하도록 설득함. 이 회의는 ‘AI라는 이름의 탄생’, 목표 설정, 초기 성공과 이를 이끈 인물들을 규정한 순간으로 평가됨.  \n",
            "[출처: 다트머스 컨퍼런스 1956년: AI의 탄생]\n",
            "\n",
            "죄송하지만, 제가 가진 정보 내에서는 답변을 찾을 수 없습니다.\u001b[0m\u001b[32;1m\u001b[1;3m아래는 요청하신 두 부분(다트머스 워크숍의 주요 내용, 그리고 존 매카시의 최근(=최신) 근황)에 대한 요약입니다.\n",
            "\n",
            "1) 다트머스 워크숍(1956) — 주요 내용\n",
            "- 언제·어디서: 1956년 여름, 미국 다트머스 대학(Dartmouth College)에서 개최된 여름 연구회(통칭 다트머스 워크숍).  \n",
            "- 주최·주요 기획자: 존 매카시(John McCarthy), 마빈 민스키(Marvin Minsky), 클로드 섀넌(Claude Shannon), 네이선 로체스터(Nathan Rochester) 등이 핵심 기획을 맡았습니다.  \n",
            "- 핵심 제안: 제안서에서는 “학습의 모든 면 또는 지능의 다른 모든 특성을 기계로 정밀하게 기술하고 시뮬레이션할 수 있다”는 낙관적 전제를 바탕으로, 여름 동안 AI(artificial intelligence) 연구를 공동으로 추진하자고 제안했습니다.  \n",
            "- 참가자(대표적): 앨런 뉴웰(Allen Newell), 허버트 사이먼(Herbert A. Simon), 아서 새뮤얼(Arthur Samuel), 올리버 셀프리지(Oliver Selfridge) 등 초기 AI 연구자들이 참가했습니다.  \n",
            "- 주요 성과·의의:\n",
            "  - 이 회의는 “인공지능(Artificial Intelligence)”이라는 연구 분야 명칭을 확정하고, 분야의 출발점으로 널리 인정됩니다.  \n",
            "  - 기호적(symbolic) 추론, 문제 해결, 학습 등 초기 연구 방향이 설정되었고, 이후 수년간의 연구·프로그램(예: 뉴웰·사이먼의 Logic Theorist 등)에 직접적 영향을 주었습니다.  \n",
            "  - 초기의 낙관적 기대는 이후 실용적 한계로 인해 ‘AI 겨울’ 등 부침을 겪기도 했지만, 다트머스 회의는 AI를 독립 학문영역으로 성립시킨 역사적 사건으로 평가됩니다.\n",
            "\n",
            "2) 존 매카시(John McCarthy) — 최신 근황(요약)\n",
            "- 사망: 존 매카시는 1927년 출생이며, 2011년 10월 24일(미국 스탠퍼드) 별세했습니다. 따라서 “최근 근황”으로서의 활동은 더 이상 없습니다.  \n",
            "- 주요 업적·경력 요약:\n",
            "  - 인공지능 분야의 창시자 가운데 한 명으로 평가됩니다. 다트머스 워크숍 기획에 참여했고, 분야 명칭의 확립에 기여했습니다.  \n",
            "  - 1958년 LISP 언어를 고안하여 AI 연구와 기호적 처리에 큰 영향을 미쳤습니다.  \n",
            "  - 시간공유 시스템, 논리적 추론(예: 공통상식 추론을 위한 이론들—circumscription 등) 등 여러 기본 개념에 기여했습니다.  \n",
            "  - 1971년 튜링상(Turing Award)을 수상했고, 오랫동안 스탠퍼드 대학 등에서 연구·교육 활동을 했습니다.  \n",
            "- 유산: 매카시의 연구(용어 정립, LISP, 형식화 접근 등)는 현대 AI의 기초를 형성했으며, 후속 세대 연구자들에게 큰 영향을 주었습니다.\n",
            "\n",
            "원하시면 다트머스 회의 원문 제안서(요지)나 매카시의 대표 논문(예: LISP 관련, circumscription 논문), 또는 주요 연대기(타임라인)를 더 자세히 정리해 드리겠습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "--------------------------------------------------\n",
            "최종 답변: 아래는 요청하신 두 부분(다트머스 워크숍의 주요 내용, 그리고 존 매카시의 최근(=최신) 근황)에 대한 요약입니다.\n",
            "\n",
            "1) 다트머스 워크숍(1956) — 주요 내용\n",
            "- 언제·어디서: 1956년 여름, 미국 다트머스 대학(Dartmouth College)에서 개최된 여름 연구회(통칭 다트머스 워크숍).  \n",
            "- 주최·주요 기획자: 존 매카시(John McCarthy), 마빈 민스키(Marvin Minsky), 클로드 섀넌(Claude Shannon), 네이선 로체스터(Nathan Rochester) 등이 핵심 기획을 맡았습니다.  \n",
            "- 핵심 제안: 제안서에서는 “학습의 모든 면 또는 지능의 다른 모든 특성을 기계로 정밀하게 기술하고 시뮬레이션할 수 있다”는 낙관적 전제를 바탕으로, 여름 동안 AI(artificial intelligence) 연구를 공동으로 추진하자고 제안했습니다.  \n",
            "- 참가자(대표적): 앨런 뉴웰(Allen Newell), 허버트 사이먼(Herbert A. Simon), 아서 새뮤얼(Arthur Samuel), 올리버 셀프리지(Oliver Selfridge) 등 초기 AI 연구자들이 참가했습니다.  \n",
            "- 주요 성과·의의:\n",
            "  - 이 회의는 “인공지능(Artificial Intelligence)”이라는 연구 분야 명칭을 확정하고, 분야의 출발점으로 널리 인정됩니다.  \n",
            "  - 기호적(symbolic) 추론, 문제 해결, 학습 등 초기 연구 방향이 설정되었고, 이후 수년간의 연구·프로그램(예: 뉴웰·사이먼의 Logic Theorist 등)에 직접적 영향을 주었습니다.  \n",
            "  - 초기의 낙관적 기대는 이후 실용적 한계로 인해 ‘AI 겨울’ 등 부침을 겪기도 했지만, 다트머스 회의는 AI를 독립 학문영역으로 성립시킨 역사적 사건으로 평가됩니다.\n",
            "\n",
            "2) 존 매카시(John McCarthy) — 최신 근황(요약)\n",
            "- 사망: 존 매카시는 1927년 출생이며, 2011년 10월 24일(미국 스탠퍼드) 별세했습니다. 따라서 “최근 근황”으로서의 활동은 더 이상 없습니다.  \n",
            "- 주요 업적·경력 요약:\n",
            "  - 인공지능 분야의 창시자 가운데 한 명으로 평가됩니다. 다트머스 워크숍 기획에 참여했고, 분야 명칭의 확립에 기여했습니다.  \n",
            "  - 1958년 LISP 언어를 고안하여 AI 연구와 기호적 처리에 큰 영향을 미쳤습니다.  \n",
            "  - 시간공유 시스템, 논리적 추론(예: 공통상식 추론을 위한 이론들—circumscription 등) 등 여러 기본 개념에 기여했습니다.  \n",
            "  - 1971년 튜링상(Turing Award)을 수상했고, 오랫동안 스탠퍼드 대학 등에서 연구·교육 활동을 했습니다.  \n",
            "- 유산: 매카시의 연구(용어 정립, LISP, 형식화 접근 등)는 현대 AI의 기초를 형성했으며, 후속 세대 연구자들에게 큰 영향을 주었습니다.\n",
            "\n",
            "원하시면 다트머스 회의 원문 제안서(요지)나 매카시의 대표 논문(예: LISP 관련, circumscription 논문), 또는 주요 연대기(타임라인)를 더 자세히 정리해 드리겠습니다.\n",
            "=======================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NeJkFq96tCvm"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}