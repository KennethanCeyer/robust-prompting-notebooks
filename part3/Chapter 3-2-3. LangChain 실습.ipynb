{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Colab Link URL**\n",
        "- https://colab.research.google.com/drive/1_qtaoytygCzRiahcq1SHZfyoy85kVT-Y?usp=sharing\n",
        "\n",
        "이 노트북은 [Google Colab](https://colab.research.google.com/)에서 실행하시기에 최적화되어있습니다.\n",
        "상기 URL을 이용해서 코드를 실행 해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf-cNs5_3V4R"
      },
      "source": [
        "## 예제 1. 기본 프롬프트 체인 다시 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 13403,
          "status": "ok",
          "timestamp": 1756078612325,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "h8oLa_dMSJHL",
        "outputId": "0efbb5c8-7329-40d3-af36-a1175192176a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/2.5 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/74.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain-core langchain-community langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {
          "elapsed": 3146,
          "status": "ok",
          "timestamp": 1756078615476,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "DJij1CkI0urN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {
          "elapsed": 439,
          "status": "ok",
          "timestamp": 1756078615915,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "JrZWAy5Y0v8H"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {
          "elapsed": 874,
          "status": "ok",
          "timestamp": 1756078616791,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "ZnExs3saU9xP"
      },
      "outputs": [],
      "source": [
        "# 1. 모델 정의\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    model=\"gpt-5-mini\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "executionInfo": {
          "elapsed": 18,
          "status": "ok",
          "timestamp": 1756078616811,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "7yHFmf8wU_cR"
      },
      "outputs": [],
      "source": [
        "# 2. 각 체인 링크에 대한 프롬프트 템플릿 정의\n",
        "prompt_summarize = ChatPromptTemplate.from_template(\n",
        "    \"다음 기술 문서를 세 문장으로 간결하게 요약해주세요:\\n\\n[원본 문서]\\n{document}\"\n",
        ")\n",
        "\n",
        "prompt_create_script = ChatPromptTemplate.from_template(\n",
        "    \"다음 요약문을 바탕으로, 비즈니스팀을 위한 1분 발표 스크립트를 작성해주세요:\\n\\n[요약문]\\n{summary}\"\n",
        ")\n",
        "\n",
        "prompt_extract_keywords = ChatPromptTemplate.from_template(\n",
        "    \"다음 발표 스크립트에서 가장 중요한 핵심 키워드 5개를 쉼표(,)로 구분하여 나열해주세요:\\n\\n[발표 스크립트 전문]\\n{script}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1756078616814,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "VyxbqztA3-Tj"
      },
      "outputs": [],
      "source": [
        "# 3. 출력 파서 정의\n",
        "# LLM의 출력(ChatMessage)에서 내용(content)만 추출하여 문자열로 변환한다.\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1756078616822,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "PwIdmHiMPYlp"
      },
      "outputs": [],
      "source": [
        "# 4. 파이프( | )를 사용하여 전체 체인 구성\n",
        "# {\"summary\": summarize_chain} 구문은 summarize_chain의 결과를 다음 체인의 'summary' 입력으로 전달하라는 의미이다.\n",
        "summarize_chain = prompt_summarize | llm | output_parser\n",
        "script_chain = {\"summary\": summarize_chain} | prompt_create_script | llm | output_parser\n",
        "keyword_chain = {\"script\": script_chain} | prompt_extract_keywords | llm | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 23052,
          "status": "ok",
          "timestamp": 1756078639875,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "Ywq0m8OI17qD",
        "outputId": "e00dc282-9ed3-4e90-b6d5-92bb7def768a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================\n",
            "LangChain으로 구성된 체인 실행 완료\n",
            "최종 추출 키워드: 검색 증강 생성(RAG), 환각, 벡터 DB, 근거 기반 답변, 출처 명시\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# --- 체인 실행 ---\n",
        "original_document = \"\"\"\n",
        "검색 증강 생성(Retrieval-Augmented Generation, RAG)은 대규모 언어 모델(LLM)의 할루시네이션(환각) 현상을 줄이고, 답변의 근거를 외부의 최신 정보에 두기 위한 강력한 아키텍처이다. RAG는 사용자의 질문이 들어오면 LLM이 바로 답변을 생성하는 것이 아니라, 먼저 외부 지식 소스(예: 벡터 데이터베이스)에서 질문과 관련성 높은 문서를 실시간으로 검색(Retrieve)한다. 그런 다음, 검색된 최신 문서를 원래의 질문과 함께 프롬프트에 포함하여 LLM에게 전달함으로써, 모델이 외부의 사실적 근거를 바탕으로 답변을 생성(Generate)하도록 유도한다. 이 방식은 LLM의 내부 학습 데이터가 특정 시점에 고정되어 발생하는 정보의 시의성 부족과 부정확성 문제를 효과적으로 해결하며, 답변의 출처를 명시할 수 있어 신뢰도를 높인다.\n",
        "\"\"\"\n",
        "\n",
        "# 최종 체인(keyword_chain)에 초기 입력을 전달하여 실행한다.\n",
        "final_keywords = keyword_chain.invoke({\"document\": original_document})\n",
        "\n",
        "print(\"========================================\")\n",
        "print(\"LangChain으로 구성된 체인 실행 완료\")\n",
        "print(f\"최종 추출 키워드: {final_keywords}\")\n",
        "print(\"========================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3Rrm10c3R8T"
      },
      "source": [
        "## 예제 2: 간단한 RAG(검색 증강 생성) 체인 구축하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6343,
          "status": "ok",
          "timestamp": 1756078646216,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "MSCkzE9q2Lz0",
        "outputId": "46b10ab5-ff3c-4464-af0b-c507d25d58fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q beautifulsoup4 faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 336,
          "status": "ok",
          "timestamp": 1756078646550,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "AwKRarIw2YjS",
        "outputId": "ac5495a8-5957-44a0-9968-45fe05659805"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "executionInfo": {
          "elapsed": 438,
          "status": "ok",
          "timestamp": 1756078646987,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "dzy_bvMY2Z9D"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "executionInfo": {
          "elapsed": 831,
          "status": "ok",
          "timestamp": 1756078647818,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "6iGJOqEQ2oQx"
      },
      "outputs": [],
      "source": [
        "# 1. 데이터 로드 (Load): 웹 페이지의 내용을 불러온다.\n",
        "loader = WebBaseLoader(\"https://www.anthropic.com/engineering/building-effective-agents\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "executionInfo": {
          "elapsed": 7,
          "status": "ok",
          "timestamp": 1756078647829,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "B6DiM1hx2pl_"
      },
      "outputs": [],
      "source": [
        "# 2. 텍스트 분할 (Split): 불러온 문서를 의미 있는 작은 조각(Chunk)으로 나눈다.\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "executionInfo": {
          "elapsed": 1968,
          "status": "ok",
          "timestamp": 1756078649799,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "Mq9rsbMo2qvR"
      },
      "outputs": [],
      "source": [
        "# 3. 임베딩 및 벡터 저장소 생성 (Embed & Store): 각 텍스트 조각을 벡터로 변환하고, 검색 가능한 벡터 저장소에 저장한다.\n",
        "vectorstore = FAISS.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1756078649800,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "P9x75urR2uAo"
      },
      "outputs": [],
      "source": [
        "# 4. 검색기(Retriever) 생성: 벡터 저장소에서 관련성 높은 문서를 검색하는 객체를 만든다.\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1756078649808,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "cQinvNQB21rv"
      },
      "outputs": [],
      "source": [
        "# 5. RAG 프롬프트 템플릿 정의\n",
        "# 검색된 문서(context)와 사용자 질문(question)을 모두 입력으로 받는다.\n",
        "prompt_rag = ChatPromptTemplate.from_template(\n",
        "    \"\"\"당신은 주어진 문맥을 바탕으로 질문에 답변하는 AI 어시스턴트입니다.\n",
        "문맥의 내용만을 사용하여 답변해주세요.\n",
        "\n",
        "\n",
        "문맥: {context}\n",
        "\n",
        "질문: {question}\n",
        "\n",
        "답변:\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "executionInfo": {
          "elapsed": 14,
          "status": "ok",
          "timestamp": 1756078649826,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "MZlK0JyM23yX"
      },
      "outputs": [],
      "source": [
        "# 6. RAG 체인 구성\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    model=\"gpt-5\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1756078649828,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "FYAiq0BN26ZH"
      },
      "outputs": [],
      "source": [
        "# 검색된 문서들을 하나의 문자열로 합치는 함수\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "executionInfo": {
          "elapsed": 7,
          "status": "ok",
          "timestamp": 1756078649838,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "ByIn4Vmq28hX"
      },
      "outputs": [],
      "source": [
        "# LCEL을 사용하여 RAG 체인을 선언적으로 구성한다.\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt_rag\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 25672,
          "status": "ok",
          "timestamp": 1756078675512,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "XtMwtWwL29aR",
        "outputId": "662a5657-29d9-4b44-e12f-517a4cd31de0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================\n",
            "질문: 에이전트를 효과적으로 구성하기 위해 검토할 사항이 뭐가 있을까요?\n",
            "답변: 다음 사항을 점검하면 에이전트를 효과적으로 구성할 수 있습니다.\n",
            "\n",
            "- 문제 적합성: 대화와 행동이 모두 필요한 업무, 성공 기준이 명확하고 피드백 루프와 인간 감독이 가능한 업무를 우선 선정.\n",
            "- 모델 역량 전제: 복잡한 입력 이해, 추론·계획, 도구의 신뢰성 있는 사용, 오류로부터의 회복.\n",
            "- 단순성 우선: 간단한 프롬프트로 시작해 평가로 성능을 측정하고, 단순한 해법이 부족할 때만 다단계 에이전틱 설계를 추가.\n",
            "- 투명성: 에이전트의 계획 단계를 명시적으로 드러내기.\n",
            "- ACI(Agent-Computer Interface) 설계: 도구의 구조를 정확히 정의하고, 문서화와 테스트로 신뢰성을 확보.\n",
            "- 도구 프롬프트 엔지니어링: 외부 서비스/API 상호작용을 위해 도구의 정확한 스키마를 제공.\n",
            "- 실행 중 검증: 각 단계마다 도구 호출 결과나 코드 실행 등 환경으로부터 “그라운드 트루스”를 받아 진행 상황을 평가.\n",
            "- 인간 참여: 체크포인트나 장애 상황에서 사용자 피드백을 받는 절차 마련.\n",
            "- 중단 조건: 최대 반복 횟수 등 명시적 스토핑 조건 설정.\n",
            "- 운영 방식: 사용자의 명령/대화로 과업을 명확히 한 뒤 독립적으로 계획·실행하되 필요 시 사용자에게 재질의.\n",
            "- 성능 관리: 측정과 반복을 통해 개선하고, 복잡성 추가는 실제 성과 향상 시에만.\n",
            "- 프로덕션 고려: 프레임워크로 빠르게 시작하되, 필요하면 추상화 레이어를 줄이고 기본 컴포넌트로 전환.\n",
            "- 활용 예 기준: \n",
            "  - 고객지원: 챗봇 인터페이스에 도구를 결합하고 의미 있는 인간 감독을 통합.\n",
            "  - 코딩 에이전트: 자동 테스트로 검증 가능, 테스트 결과로 반복 개선, 객관적 품질 측정, 광범위한 요구 정렬을 위한 인간 검토 유지.\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# --- RAG 체인 실행 ---\n",
        "question = \"에이전트를 효과적으로 구성하기 위해 검토할 사항이 뭐가 있을까요?\"\n",
        "final_answer = rag_chain.invoke(question)\n",
        "\n",
        "print(\"========================================\")\n",
        "print(f\"질문: {question}\")\n",
        "print(f\"답변: {final_answer}\")\n",
        "print(\"========================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1756078675513,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "eTLMsbU03AJh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMiM8F2ogJbFrrBnUVWku5a",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
