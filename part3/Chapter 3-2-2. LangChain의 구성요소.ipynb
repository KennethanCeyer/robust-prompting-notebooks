{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Colab Link URL**\n",
        "- https://colab.research.google.com/drive/10Yybx2Wx6cBz3RLQemRwTmhgKiCZFqvL?usp=sharing\n",
        "\n",
        "이 노트북은 [Google Colab](https://colab.research.google.com/)에서 실행하시기에 최적화되어있습니다.\n",
        "상기 URL을 이용해서 코드를 실행 해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 22823,
          "status": "ok",
          "timestamp": 1756078650021,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "h8oLa_dMSJHL",
        "outputId": "4165daaf-6e84-48b8-e303-c1b7da6d8148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain-core langchain-community langchain-openai faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {
          "elapsed": 6602,
          "status": "ok",
          "timestamp": 1756078656621,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "AmzaPqh50yP0"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {
          "elapsed": 540,
          "status": "ok",
          "timestamp": 1756078657164,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "O_VuPA-f0zff"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5385,
          "status": "ok",
          "timestamp": 1756078662551,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "ZnExs3saU9xP",
        "outputId": "43f11b93-7e3a-4ab5-f3cc-ce5dce00d7d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "대한민국의 수도는 서울특별시(서울)입니다. 다만 행정 기능 일부는 세종특별자치시로 이전되어 정부 부처 일부가 세종에 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# OpenAI의 gpt-5-mini 모델을 사용하는 모델 객체 생성\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    model=\"gpt-5-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 표준화된 .invoke() 메서드로 모델 호출\n",
        "response = llm.invoke(\"대한민국의 수도는 어디인가요?\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 168,
          "status": "ok",
          "timestamp": 1756078662723,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "7yHFmf8wU_cR",
        "outputId": "68d09c3e-4613-4605-c291-0d9d7ab5ef03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[HumanMessage(content='인공지능에 대해 한국어로 간략히 설명해주세요.', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "# Prompts 구성 요소 사용 예시\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# {topic}과 {language}라는 두 개의 입력 변수를 가진 프롬프트 템플릿 생성\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"{topic}에 대해 {language}로 간략히 설명해주세요.\"\n",
        ")\n",
        "\n",
        "# 템플릿에 변수 값을 채워 실제 프롬프트를 생성\n",
        "prompt_filled = prompt_template.format_prompt(topic=\"인공지능\", language=\"한국어\")\n",
        "print(prompt_filled.to_messages())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 61,
          "status": "ok",
          "timestamp": 1756078662788,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "zIU8BiWhVMOa",
        "outputId": "f3b79181-f8b1-4159-d378-d55ee9d31af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "['SpaceX', 'Tesla']\n"
          ]
        }
      ],
      "source": [
        "# Output Parsers 구성 요소 사용 예시\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "# JSON 형식으로 답변을 생성하도록 유도하는 프롬프트\n",
        "json_prompt = \"다음 인물에 대한 정보를 JSON 형식으로 제공해줘: Elon Musk\"\n",
        "# LLM이 생성한 JSON 문자열을 파이썬 딕셔너리로 변환하는 파서\n",
        "json_parser = JsonOutputParser()\n",
        "\n",
        "# 가상의 LLM 출력 (실제로는 llm.invoke의 결과)\n",
        "llm_output_string = '{\"name\": \"Elon Musk\", \"company\": [\"SpaceX\", \"Tesla\"], \"known_for\": [\"electric cars\", \"reusable rockets\"]}'\n",
        "\n",
        "# 파서를 사용하여 문자열을 딕셔너리로 변환\n",
        "parsed_output = json_parser.parse(llm_output_string)\n",
        "\n",
        "print(type(parsed_output))\n",
        "print(parsed_output['company'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7540,
          "status": "ok",
          "timestamp": 1756078670326,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "Z4yhHYcH236E",
        "outputId": "40b8702a-63c3-463f-91e2-aff4dfc1a848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A large language model (LLM) is a type of AI trained on vast amounts of text to predict and generate human-like language. Key points:\n",
            "\n",
            "- Architecture and training: Most modern LLMs use the transformer architecture and are pretrained on huge text corpora to learn patterns of grammar, facts, and style. They are often later fine-tuned for specific tasks.\n",
            "- How they work: Given some input text, they predict the most likely next words (autoregressive models) or fill in masked words (masked-language models), enabling generation, completion, and understanding of language.\n",
            "- Capabilities: They can write and summarize text, translate languages, answer questions, generate code, and help with brainstorming or tutoring.\n",
            "- Limitations and risks: They can produce incorrect or misleading information (“hallucinations”), reflect biases present in training data, and may leak sensitive information. They do not possess true understanding or consciousness.\n",
            "- Practical use and safety: Effective use often combines human oversight, prompt engineering, fine-tuning, and safety controls (content filters, auditing) to reduce errors and harms.\n",
            "\n",
            "Examples of LLMs include GPT-series (GPT-3/4), BERT, PaLM, and LLaMA.\n"
          ]
        }
      ],
      "source": [
        "# LCEL 사용 예시\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "\n",
        "# 앞서 정의한 구성 요소들을 파이프로 연결한다.\n",
        "chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "# 체인 실행\n",
        "result = chain.invoke({\"topic\": \"대규모 언어 모델\", \"language\": \"영어\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4437,
          "status": "ok",
          "timestamp": 1756078674776,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "VyxbqztA3-Tj",
        "outputId": "a26bddcf-15f1-4860-b6b2-e561274853c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "로봇공학, 소프트웨어 공학, 사회적 영향 연구 등의 컴퓨터 과학의 여러 하위 분야에서 LLM의 사용 증가로 이어졌다.[16] 2024년에는 오픈AI가 논리적 추론 기능을 강화한 모델 OpenAI o1을 출시했으며, 이 모델은 최종 답변을 생성하기 전에 장문의 사고 과정(Chains of Thought)을 먼저 생성하는 특징이 있다.\n"
          ]
        }
      ],
      "source": [
        "# Retrieval 구성 요소 사용 예시\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from google.colab import userdata\n",
        "\n",
        "# 1. Load: 웹 페이지 로더로 '대형 언어 모델' 위키피디아 문서 로드\n",
        "loader = WebBaseLoader(\"https://ko.wikipedia.org/wiki/%EB%8C%80%ED%98%95_%EC%96%B8%EC%96%B4_%EB%AA%A8%EB%8D%B8\")\n",
        "docs = loader.load()\n",
        "\n",
        "# 2. Split: 텍스트 분할기로 문서를 500자 단위로 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# 3. Embed & Store: OpenAI 임베딩 모델과 FAISS 벡터 저장소 생성\n",
        "# 분할된 문서들은 벡터로 변환되어 FAISS에 저장된다.\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY))\n",
        "\n",
        "# 4. Retrieve: 검색기(Retriever)를 생성하고 관련 문서 검색\n",
        "retriever = vectorstore.as_retriever()\n",
        "retrieved_docs = retriever.invoke(\"LLM의 문제점은 무엇인가?\")\n",
        "\n",
        "# 검색된 문서의 내용 중 첫 번째 문서의 일부를 출력\n",
        "print(retrieved_docs[0].page_content[:200]) # 출력 내용이 길어 일부만 표시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "executionInfo": {
          "elapsed": 9,
          "status": "ok",
          "timestamp": 1756078674791,
          "user": {
            "displayName": "Sungmin Han",
            "userId": "16133717747299446002"
          },
          "user_tz": -540
        },
        "id": "iGORks-hWUmk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMPiD6fCBbgj0AwWXMXEtFz",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
